# -*- coding: utf-8 -*-


import os
import re
import json
import time
import pickle
import argparse
from typing import List, Dict, Any, Tuple
from datetime import datetime

import jieba
from rank_bm25 import BM25Okapi
from openai import OpenAI

# ================= é…ç½®ä¸å¸¸é‡ =================

# ä¸Šä¸‹æ–‡ç®¡ç†å¸¸é‡ï¼ˆé’ˆå¯¹ DeepSeek çš„ token é™åˆ¶ï¼‰
MAX_CONTEXT_TOKENS = 4096  # DeepSeek context window
CRITERIA_HEAD_KEEP = 8     # ä¿ç•™å‰ N æ¡ï¼ˆæ ¸å¿ƒç–¾ç—…å®šä¹‰ï¼‰
CRITERIA_TAIL_KEEP = 4     # ä¿ç•™å N æ¡ï¼ˆå…³é”®ç¦å¿Œç—‡ã€å­•å¦‡ã€è¿‡æ•ç­‰ï¼‰

# ä¸­æ–‡åœç”¨è¯ï¼ˆç”¨äº BM25ï¼‰
STOPWORDS = set([
    "çš„", "äº†", "å’Œ", "æˆ–", "ä¸", "åŠ", "ä»¥åŠ", "ç­‰",
    "ç ”ç©¶", "è¯•éªŒ", "ä¸´åºŠ", "æ‚£è€…", "æ–¹æ¡ˆ", "æ²»ç–—", "è¯„ä¼°", "è§‚å¯Ÿ",
    "éšæœº", "å¯¹ç…§", "å¤šä¸­å¿ƒ", "å…¥ç»„", "æ’é™¤", "çº³å…¥", "å—è¯•è€…",
    "ç¬¦åˆ", "æ»¡è¶³", "å…·æœ‰", "è¿›è¡Œ", "æ¥å—", "å®Œæˆ",
])

# ================= å·¥å…·å‡½æ•° =================

def normalize_text(s: str) -> str:
    """æ–‡æœ¬æ ‡å‡†åŒ–"""
    if not s:
        return ""
    s = s.replace("\u3000", " ")
    s = re.sub(r"\s+", " ", s).strip()
    return s

def tokenize_zh(text: str) -> List[str]:
    """
    ä¸­æ–‡åˆ†è¯ï¼ˆç”¨äº BM25ï¼‰
    - jieba åˆ†è¯
    - å»åœç”¨è¯
    - å»çŸ­è¯ï¼ˆ< 2å­—ç¬¦ï¼‰
    """
    text = normalize_text(text)
    if not text:
        return []
    
    tokens = jieba.lcut(text)
    result = []
    
    for token in tokens:
        token = token.strip()
        if not token:
            continue
        if token in STOPWORDS:
            continue
        if len(token) < 2:
            continue
        result.append(token)
    
    return result

# ================= æ•°æ®åŠ è½½ä¸ç´¢å¼• =================

def load_trials(data_dir: str, max_trials: int = 0) -> List[Dict[str, Any]]:
    """
    åŠ è½½æ¸…æ´—åçš„ trial æ•°æ®
    
    Args:
        data_dir: åŒ…å« *.jsonl æ–‡ä»¶çš„ç›®å½•
        max_trials: æœ€å¤šåŠ è½½æ•°é‡ï¼ˆ0 = å…¨éƒ¨ï¼‰
    
    Returns:
        List[Dict]: trial åˆ—è¡¨
    """
    trials = []
    
    # æŸ¥æ‰¾æ‰€æœ‰ jsonl æ–‡ä»¶
    files = []
    for fname in os.listdir(data_dir):
        if fname.lower().endswith(".jsonl"):
            files.append(os.path.join(data_dir, fname))
    
    if not files:
        raise FileNotFoundError(f"âŒ åœ¨ {data_dir} ä¸­æ‰¾ä¸åˆ° .jsonl æ–‡ä»¶")
    
    files.sort()  # ç¡®ä¿é¡ºåºä¸€è‡´
    
    print(f"ğŸ“‚ æ‰¾åˆ° {len(files)} ä¸ªæ•°æ®æ–‡ä»¶")
    
    for fpath in files:
        with open(fpath, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                
                try:
                    trial = json.loads(line)
                    trials.append(trial)
                    
                    if max_trials and len(trials) >= max_trials:
                        return trials
                except Exception as e:
                    print(f"âš ï¸ è§£æå¤±è´¥: {e}")
                    continue
    
    return trials

def build_bm25_text(trial: Dict[str, Any]) -> str:
    """
    æ„å»ºç”¨äº BM25 æ£€ç´¢çš„æ–‡æ¡£æ–‡æœ¬
    
    ç­–ç•¥ï¼š
    - ä¾§é‡æ ‡é¢˜å’Œç–¾ç—…ï¼ˆé«˜æƒé‡å­—æ®µï¼‰
    - å…¥æ’æ ‡å‡†åªå–å‰5æ¡ï¼ˆå‡å°‘å™ªéŸ³ï¼‰
    - é€‚å½“åŒ…å«å¹²é¢„æªæ–½
    """
    bg = trial.get("background", {}) or {}
    cr = trial.get("criteria", {}) or {}
    
    # åŸºç¡€å­—æ®µ
    public_title = bg.get("public_title", "") or ""
    scientific_title = bg.get("scientific_title", "") or ""
    conditions = " ".join(bg.get("conditions", []) or [])
    interventions = " ".join(bg.get("interventions", []) or [])
    brief_summary = bg.get("brief_summary", "") or ""
    
    # å…¥æ’æ ‡å‡†ï¼ˆæˆªæ–­ä»¥å‡å°‘å™ªéŸ³ï¼‰
    inclusion = cr.get("inclusion", []) or []
    exclusion = cr.get("exclusion", []) or []
    inc_text = " ".join(inclusion[:5])
    exc_text = " ".join(exclusion[:5])
    
    # ç»„åˆ
    parts = [
        public_title,
        scientific_title,
        conditions,
        interventions,
        brief_summary,
        inc_text,
        exc_text,
    ]
    
    return normalize_text(" ".join(filter(None, parts)))

def get_bm25_instance(trials: List[Dict[str, Any]], cache_dir: str) -> BM25Okapi:
    """
    æ„å»ºæˆ–åŠ è½½ BM25 ç´¢å¼•
    
    Args:
        trials: trial åˆ—è¡¨
        cache_dir: ç¼“å­˜ç›®å½•
    
    Returns:
        BM25Okapi å®ä¾‹
    """
    os.makedirs(cache_dir, exist_ok=True)
    cache_file = os.path.join(cache_dir, f"bm25_index_{len(trials)}.pkl")
    
    # å°è¯•åŠ è½½ç¼“å­˜
    if os.path.exists(cache_file):
        print(f"ğŸ“¦ ä»ç¼“å­˜åŠ è½½ BM25 ç´¢å¼•: {cache_file}")
        with open(cache_file, "rb") as f:
            return pickle.load(f)
    
    # æ„å»ºæ–°ç´¢å¼•
    print(f"ğŸ”¨ æ„å»º BM25 ç´¢å¼•ï¼ˆå…± {len(trials)} ä¸ªè¯•éªŒï¼‰...")
    
    corpus = []
    for i, trial in enumerate(trials):
        if (i + 1) % 5000 == 0:
            print(f"   è¿›åº¦: {i + 1}/{len(trials)}")
        
        text = build_bm25_text(trial)
        tokens = tokenize_zh(text)
        corpus.append(tokens)
    
    bm25 = BM25Okapi(corpus)
    
    # ä¿å­˜ç¼“å­˜
    with open(cache_file, "wb") as f:
        pickle.dump(bm25, f)
    
    print(f"âœ… BM25 ç´¢å¼•å·²æ„å»ºå¹¶ç¼“å­˜")
    return bm25

# ================= æ ¸å¿ƒæ”¹è¿›ï¼šæ™ºèƒ½ä¸Šä¸‹æ–‡å‰ªè£ =================

def smart_truncate_list(items: List[str], head: int, tail: int) -> List[str]:
    """
    æ™ºèƒ½æˆªæ–­ç­–ç•¥ - Head+Tail
    
    å®¡ç¨¿äººå…³æ³¨ç‚¹ï¼š
    - Headï¼ˆå‰Næ¡ï¼‰ï¼šé€šå¸¸æ˜¯æ ¸å¿ƒç–¾ç—…å®šä¹‰ã€ä¸»è¦è¯Šæ–­æ ‡å‡†
    - Tailï¼ˆåNæ¡ï¼‰ï¼šé€šå¸¸æ˜¯å…³é”®ç¦å¿Œç—‡ï¼ˆå­•å¦‡ã€è¿‡æ•ã€ä¸¥é‡å¹¶å‘ç—‡ç­‰ï¼‰
    - Middleï¼ˆä¸­é—´ï¼‰ï¼šé€šå¸¸æ˜¯å¸¸è§„å®éªŒå®¤æŒ‡æ ‡ï¼Œä¼˜å…ˆçº§è¾ƒä½
    
    Args:
        items: å®Œæ•´åˆ—è¡¨
        head: ä¿ç•™å‰å‡ æ¡
        tail: ä¿ç•™åå‡ æ¡
    
    Returns:
        æˆªæ–­åçš„åˆ—è¡¨
    """
    if not items:
        return []
    
    # å¦‚æœæ€»æ•°ä¸è¶…è¿‡é™åˆ¶ï¼Œç›´æ¥è¿”å›
    if len(items) <= (head + tail):
        return items
    
    # Head + çœç•¥æ ‡è®° + Tail
    truncated = (
        items[:head] +
        [f"... [çœç•¥ä¸­é—´ {len(items) - head - tail} æ¡éå…³é”®æ¡æ¬¾] ..."] +
        items[-tail:]
    )
    
    return truncated

def format_trial_for_llm(trial: Dict[str, Any]) -> str:
    """
    å°† trial æ ¼å¼åŒ–ä¸º LLM å‹å¥½çš„æ–‡æœ¬
    
    æ”¹è¿›ç‚¹ï¼š
    1. ä½¿ç”¨ smart_truncate_list è€Œéç²—æš´æˆªæ–­
    2. æ¸…æ™°çš„ç»“æ„åŒ–æ ¼å¼
    3. ä¿ç•™æœ€é‡è¦çš„ä¿¡æ¯
    """
    trial_id = trial.get("trial_id", "Unknown")
    bg = trial.get("background", {}) or {}
    cr = trial.get("criteria", {}) or {}
    meta = trial.get("meta", {}) or {}
    
    # åŸºç¡€ä¿¡æ¯
    title = bg.get("public_title") or bg.get("scientific_title") or "N/A"
    phase = meta.get("phase", "") or "N/A"
    conditions = bg.get("conditions", []) or []
    interventions = bg.get("interventions", []) or []
    
    # æ™ºèƒ½æˆªæ–­å…¥æ’æ ‡å‡†
    inclusion_raw = cr.get("inclusion", []) or []
    exclusion_raw = cr.get("exclusion", []) or []
    
    inclusion = smart_truncate_list(inclusion_raw, CRITERIA_HEAD_KEEP, CRITERIA_TAIL_KEEP)
    exclusion = smart_truncate_list(exclusion_raw, CRITERIA_HEAD_KEEP, CRITERIA_TAIL_KEEP)
    
    # æ ¼å¼åŒ–
    def format_list(lst):
        return "\n".join([f"  - {item}" for item in lst])
    
    context = f"""Trial ID: {trial_id}
Title: {title}
Phase: {phase}
Conditions: {', '.join(conditions) if conditions else 'N/A'}
Interventions: {', '.join(interventions[:5]) if interventions else 'N/A'}

[Inclusion Criteria]
{format_list(inclusion) if inclusion else '  - N/A'}

[Exclusion Criteria]
{format_list(exclusion) if exclusion else '  - N/A'}
"""
    
    return context

# ================= æ ¸å¿ƒæ”¹è¿›ï¼šé²æ£’çš„ LLM Prompt =================

LLM_SYSTEM_PROMPT = """You are a Clinical Trial Matching Assistant with medical expertise.

**Your Task**: Compare the Patient Profile with the Clinical Trial Protocol and make a matching decision.

**Decision Logic**:
1. **Included**: 
   - Patient likely MEETS the main inclusion criteria based on available information
   - AND has NO obvious exclusion factors
   - Make reasonable clinical judgments when minor details are missing
   - If disease type, stage, and key biomarkers match, lean towards Included

2. **Excluded**: 
   - Patient clearly VIOLATES at least one major exclusion criterion
   - OR clearly FAILS to meet critical inclusion criteria (e.g., wrong disease, wrong stage)
   - Disease type mismatch or obvious contraindications

3. **Insufficient**: 
   - Patient profile LACKS CRITICAL information that makes ANY judgment impossible
   - Examples: Disease type unknown, stage completely missing for stage-specific trials, no biomarker data when trial specifically requires it
   - ONLY use when truly cannot make a reasonable medical judgment
   - NOT for minor missing details (e.g., exact body temperature, specific lab test dates)

**Output Requirements**:
You MUST output a valid JSON object with these exact fields:
{
  "label": "Included" | "Excluded" | "Insufficient",
  "score": <number 0-100>,
  "reason": "<Brief summary in Chinese, 1-2 sentences>",
  "evidence": "<Quote the SPECIFIC criteria text that led to this decision>"
}

**Score Guidelines**:
- Excluded: 0-40 (clear mismatch or contraindication)
- Insufficient: 40-60 (truly missing critical core information)
- Included: 60-100 (reasonable match, higher = stronger match)

**Critical Rules**:
- ALWAYS quote specific criteria in "evidence"
- Make reasonable clinical judgments - missing minor details should NOT lead to Insufficient
- Choose "Insufficient" ONLY when core diagnostic information is missing
- Never fabricate information not in the patient profile
- Focus on practical trial matching, not information perfection
- When in doubt between Included and Insufficient, if core info (disease, stage, key biomarkers) is present, lean towards Included
"""

def llm_rerank(
    client: OpenAI,
    model: str,
    patient_text: str,
    candidates: List[Dict[str, Any]]
) -> List[Dict[str, Any]]:
    """
    ä½¿ç”¨ LLM å¯¹å€™é€‰è¯•éªŒè¿›è¡Œé‡æ’åº
    
    æ”¹è¿›ç‚¹ï¼š
    1. å¼ºåˆ¶ JSON è¾“å‡ºæ¨¡å¼
    2. è¦æ±‚ evidence å¼•ç”¨
    3. è¯¦ç»†çš„è¿›åº¦æ˜¾ç¤º
    4. æ›´å¥½çš„é”™è¯¯å¤„ç†
    
    Args:
        client: OpenAI client
        model: æ¨¡å‹åç§°
        patient_text: æ‚£è€…æè¿°
        candidates: å€™é€‰è¯•éªŒåˆ—è¡¨
    
    Returns:
        æ’åºåçš„ç»“æœåˆ—è¡¨
    """
    results = []
    total = len(candidates)
    
    print(f"\nğŸ¤– å¼€å§‹ AI åˆ†æï¼ˆå…± {total} ä¸ªå€™é€‰ï¼Œæ¨¡å‹: {model}ï¼‰...")
    print("=" * 70)
    
    for i, trial in enumerate(candidates, 1):
        trial_context = format_trial_for_llm(trial)
        
        user_message = f"""[Patient Profile]
{patient_text}

[Clinical Trial Protocol]
{trial_context}

Please evaluate the match and output JSON."""
        
        try:
            start_time = time.time()
            
            # å¼ºåˆ¶ JSON è¾“å‡ºæ¨¡å¼ï¼ˆDeepSeek æ”¯æŒï¼‰
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": LLM_SYSTEM_PROMPT},
                    {"role": "user", "content": user_message}
                ],
                response_format={"type": "json_object"},  # å¼ºåˆ¶ JSON
                temperature=0.0,  # ç¡®ä¿ä¸€è‡´æ€§
            )
            
            latency = time.time() - start_time
            
            # è§£æå“åº”
            content = response.choices[0].message.content
            parsed = json.loads(content)
            
            # æå–å­—æ®µ
            label = parsed.get("label", "Insufficient")
            score = float(parsed.get("score", 0))
            reason = parsed.get("reason", "")
            evidence = parsed.get("evidence", "")
            
            # æ„å»ºç»“æœ
            result = {
                "trial_id": trial.get("trial_id", ""),
                "title": trial.get("background", {}).get("public_title", ""),
                "label": label,
                "score": score,
                "reason": reason,
                "evidence": evidence,
                "latency": latency,
            }
            
            results.append(result)
            
            # è¿›åº¦æ˜¾ç¤º
            status_icon = {
                "Included": "âœ…",
                "Excluded": "âŒ",
                "Insufficient": "âš ï¸"
            }.get(label, "â“")
            
            print(f"[{i:2d}/{total}] {status_icon} {trial['trial_id']:12s} | "
                  f"{label:12s} | Score: {score:5.1f} | {latency:.1f}s")
            
        except json.JSONDecodeError as e:
            print(f"[{i:2d}/{total}] âŒ JSON è§£æå¤±è´¥: {trial['trial_id']}")
            results.append({
                "trial_id": trial.get("trial_id", ""),
                "label": "Error",
                "score": 0,
                "reason": f"JSONè§£æé”™è¯¯: {str(e)}",
                "evidence": "",
                "latency": 0,
            })
        
        except Exception as e:
            print(f"[{i:2d}/{total}] âŒ å¤„ç†å¤±è´¥: {trial['trial_id']} - {str(e)}")
            results.append({
                "trial_id": trial.get("trial_id", ""),
                "label": "Error",
                "score": 0,
                "reason": f"å¤„ç†é”™è¯¯: {str(e)}",
                "evidence": "",
                "latency": 0,
            })
    
    print("=" * 70)
    
    # æŒ‰åˆ†æ•°é™åºæ’åº
    results.sort(key=lambda x: x["score"], reverse=True)
    
    return results

# ================= BM25 æ£€ç´¢ =================

def bm25_retrieve(
    bm25: BM25Okapi,
    trials: List[Dict[str, Any]],
    query: str,
    topk: int
) -> List[Dict[str, Any]]:
    """
    ä½¿ç”¨ BM25 æ£€ç´¢å€™é€‰è¯•éªŒ
    
    Args:
        bm25: BM25 ç´¢å¼•
        trials: å…¨éƒ¨è¯•éªŒ
        query: æŸ¥è¯¢æ–‡æœ¬
        topk: è¿”å›æ•°é‡
    
    Returns:
        å€™é€‰è¯•éªŒåˆ—è¡¨
    """
    query_tokens = tokenize_zh(query)
    
    if not query_tokens:
        print("âš ï¸ æŸ¥è¯¢åˆ†è¯ç»“æœä¸ºç©ºï¼Œè¯·æ£€æŸ¥è¾“å…¥")
        return []
    
    # è®¡ç®—åˆ†æ•°
    scores = bm25.get_scores(query_tokens)
    
    # æ’åºå¹¶å– topk
    indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:topk]
    
    candidates = [trials[i] for i in indices]
    
    return candidates

# ================= ä¸»ç¨‹åº =================

def main():
    parser = argparse.ArgumentParser(
        description="TrialGPT-China V2 - SIGIR Rebuttal Version",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python TrialGPT_China_V2.py --data_dir "D:\\å®ä¹ \\TrialGPT-China\\cleaned_out_V4\\clean_parts" --topk 50 --topn 10
  
  python TrialGPT_China_V2.py --data_dir "D:\\å®ä¹ \\TrialGPT-China\\cleaned_out_V4\\clean_parts" --query "æ‚£è€…æè¿°..." --topk 30

ç¯å¢ƒå˜é‡:
  DEEPSEEK_API_KEY - DeepSeek API å¯†é’¥
        """
    )
    
    parser.add_argument(
        "--data_dir",
        type=str,
        required=True,
        help="æ¸…æ´—åæ•°æ®ç›®å½•ï¼ˆåŒ…å« *.jsonl æ–‡ä»¶ï¼‰"
    )
    
    parser.add_argument(
        "--query",
        type=str,
        default="",
        help="æ‚£è€…æè¿°æ–‡æœ¬ï¼ˆä¸æä¾›åˆ™äº¤äº’å¼è¾“å…¥ï¼‰"
    )
    
    parser.add_argument(
        "--topk",
        type=int,
        default=50,
        help="BM25 å¬å›æ•°é‡ï¼ˆdefault: 50ï¼‰"
    )
    
    parser.add_argument(
        "--topn",
        type=int,
        default=10,
        help="æœ€ç»ˆè¾“å‡ºæ•°é‡ï¼ˆdefault: 10ï¼‰"
    )
    
    parser.add_argument(
        "--model",
        type=str,
        default="deepseek-chat",
        help="DeepSeek æ¨¡å‹åç§°ï¼ˆdefault: deepseek-chatï¼‰"
    )
    
    parser.add_argument(
        "--max_trials",
        type=int,
        default=0,
        help="æœ€å¤šåŠ è½½è¯•éªŒæ•°é‡ï¼ˆ0 = å…¨éƒ¨ï¼Œç”¨äºè°ƒè¯•ï¼‰"
    )
    
    parser.add_argument(
        "--save_json",
        type=str,
        default="",
        help="ä¿å­˜ç»“æœåˆ° JSON æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰"
    )
    
    args = parser.parse_args()
    
    # ===== 1. åŠ è½½æ•°æ® =====
    print("\n" + "=" * 70)
    print("TrialGPT-China V2 - Clinical Trial Matching System")
    print("=" * 70)
    print(f"\nğŸ“š [1/4] åŠ è½½æ•°æ®...")
    
    trials = load_trials(args.data_dir, max_trials=args.max_trials)
    print(f"âœ… å·²åŠ è½½ {len(trials)} ä¸ªè¯•éªŒ")
    
    # ===== 2. æ„å»º/åŠ è½½ BM25 ç´¢å¼• =====
    print(f"\nğŸ” [2/4] å‡†å¤‡æ£€ç´¢ç´¢å¼•...")
    bm25 = get_bm25_instance(trials, cache_dir="./cache")
    
    # ===== 3. è·å–æ‚£è€…æè¿° =====
    print(f"\nğŸ‘¤ [3/4] è·å–æ‚£è€…ä¿¡æ¯...")
    
    patient_text = args.query
    
    if not patient_text:
        print("è¯·è¾“å…¥æ‚£è€…æè¿°ï¼ˆè¾“å…¥ END å•ç‹¬ä¸€è¡Œç»“æŸï¼‰ï¼š")
        print("-" * 70)
        lines = []
        while True:
            try:
                line = input()
                if line.strip().upper() == "END":
                    break
                lines.append(line)
            except EOFError:
                break
        
        patient_text = normalize_text("\n".join(lines))
    
    if not patient_text:
        print("âŒ æ‚£è€…æè¿°ä¸ºç©ºï¼Œé€€å‡º")
        return
    
    print(f"âœ… æ‚£è€…æè¿°é•¿åº¦: {len(patient_text)} å­—ç¬¦")
    print(f"   é¢„è§ˆ: {patient_text[:100]}...")
    
    # ===== 4. BM25 æ£€ç´¢ + LLM é‡æ’åº =====
    print(f"\nğŸ” [4/4] æ£€ç´¢ä¸åŒ¹é…...")
    
    # BM25 å¬å›
    print(f"\nğŸ“Š BM25 æ£€ç´¢ä¸­ï¼ˆtopk={args.topk}ï¼‰...")
    candidates = bm25_retrieve(bm25, trials, patient_text, args.topk)
    print(f"âœ… BM25 å¬å› {len(candidates)} ä¸ªå€™é€‰")
    
    # æ£€æŸ¥ API Key
    api_key = os.getenv("DEEPSEEK_API_KEY", "").strip()
    if not api_key:
        print("\nâŒ é”™è¯¯: æœªè®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY")
        print("è¯·åœ¨ PowerShell æ‰§è¡Œ: setx DEEPSEEK_API_KEY \"sk-xxxx\"")
        print("ç„¶åé‡å¼€ç»ˆç«¯/VSCode")
        return
    
    # åˆå§‹åŒ– OpenAI client
    client = OpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com"
    )
    
    # LLM é‡æ’åº
    ranked_results = llm_rerank(client, args.model, patient_text, candidates)
    
    # ===== 5. è¾“å‡ºç»“æœ =====
    print("\n" + "=" * 70)
    print(f"ğŸ“‹ æœ€ç»ˆæ¨èç»“æœï¼ˆTop {args.topn}ï¼‰")
    print("=" * 70)
    
    for i, result in enumerate(ranked_results[:args.topn], 1):
        label = result["label"]
        score = result["score"]
        trial_id = result["trial_id"]
        title = result.get("title", "")
        reason = result.get("reason", "")
        evidence = result.get("evidence", "")
        
        # çŠ¶æ€å›¾æ ‡
        status_icon = {
            "Included": "âœ…",
            "Excluded": "âŒ",
            "Insufficient": "âš ï¸",
            "Error": "âŒ"
        }.get(label, "â“")
        
        print(f"\n{i}. {status_icon} [{label}] Score: {score:.1f} | ID: {trial_id}")
        
        if title:
            print(f"   æ ‡é¢˜: {title[:80]}{'...' if len(title) > 80 else ''}")
        
        print(f"   ç†ç”±: {reason}")
        
        if evidence:
            evidence_preview = evidence[:150] + "..." if len(evidence) > 150 else evidence
            print(f"   å¼•ç”¨: \"{evidence_preview}\"")
        
        print("-" * 70)
    
    # ===== 6. ä¿å­˜ç»“æœï¼ˆå¯é€‰ï¼‰=====
    if args.save_json:
        output_data = {
            "metadata": {
                "timestamp": datetime.now().isoformat(),
                "model": args.model,
                "topk": args.topk,
                "topn": args.topn,
                "total_trials": len(trials),
            },
            "patient_text": patient_text,
            "top_results": ranked_results[:args.topn],
            "all_results": ranked_results,
        }
        
        with open(args.save_json, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {args.save_json}")
    
    # ===== ç»Ÿè®¡ä¿¡æ¯ =====
    print("\n" + "=" * 70)
    print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 70)
    
    label_counts = {}
    for r in ranked_results:
        label = r["label"]
        label_counts[label] = label_counts.get(label, 0) + 1
    
    for label, count in sorted(label_counts.items()):
        print(f"  {label:12s}: {count:3d}")
    
    avg_latency = sum(r.get("latency", 0) for r in ranked_results) / len(ranked_results) if ranked_results else 0
    print(f"\n  å¹³å‡å“åº”æ—¶é—´: {avg_latency:.2f}s")
    print(f"  æ€»å¤„ç†æ—¶é—´: {sum(r.get('latency', 0) for r in ranked_results):.1f}s")
    
    print("\nâœ… å®Œæˆï¼")


if __name__ == "__main__":
    main()
